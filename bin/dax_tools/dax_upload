#!/usr/bin/env python
# -*- coding: utf-8 -*-

""" Executable to upload processed data back to XNAT from the dax upload folder """

import os
import sys
import dax
import imp
import csv
import json
import shutil
import smtplib
import getpass
from datetime import datetime
from email.mime.text import MIMEText

from dax import XnatUtils, DAX_Settings
from dax.task import READY_TO_COMPLETE, COMPLETE, UPLOADING, JOB_FAILED, JOB_PENDING, NEEDS_QA
from dax.task import ClusterTask

########### VARIABLES ###########
DAX_SETTINGS = DAX_Settings()
RESULTS_DIR = DAX_SETTINGS.get_results_dir()
JOB_EXTENSION_FILE = DAX_SETTINGS.get_job_extension_file()
DISKQ_DIR = os.path.join(RESULTS_DIR, 'DISKQ')
DISKQ_BATCH_DIR = os.path.join(DISKQ_DIR, 'BATCH')
_COMPLETE_FLAG_FILE = 'READY_TO_COMPLETE.txt'
SMTP_FROM = DAX_SETTINGS.get_smtp_from()
SMTP_HOST = DAX_SETTINGS.get_smtp_host()
SMTP_PASS = DAX_SETTINGS.get_smtp_pass()
_READY_FLAG_FILE = 'READY_TO_UPLOAD.txt'
_FAILED_FLAG_FILE = 'JOB_FAILED.txt'
_EMAILED_FLAG_FILE = 'ALREADY_SEND_EMAIL.txt'
_OUTLOG = 'OUTLOG'
_TRASH = 'TRASH'
_PBS = 'PBS'
_FLAG_FILES = 'FlagFiles'
_UPLOAD_SKIP_LIST = [_OUTLOG, _TRASH, _PBS, _FLAG_FILES]
FLAGFILE_TEMPLATE = os.path.join(RESULTS_DIR, _FLAG_FILES, 'Process_Upload_running')
SNAPSHOTS_ORIGINAL = 'snapshot_original.png'
SNAPSHOTS_PREVIEW = 'snapshot_preview.png'
DEFAULT_HEADER = ['host', 'username', 'password', 'projects']

#Cmd:
GS_CMD = """gs -q -o {original} -sDEVICE=pngalpha -dLastPage=1 {assessor_path}/PDF/*.pdf"""
CONVERT_CMD = """convert {original} -resize x200 {preview}"""

# WARNING content for emails
WARNING_START_CONTENT = """
The following assessors already exist and the Spider try to upload files on existing files :
"""
WARNING_END_CONTENT = """
You should:
    -remove the assessor if you want to upload the data
    -set the status of the assessor to "uploading"
    -remove the data from the upload folder if you do not want to upload this data.
"""
WARNING_SUBJECT = 'ERROR/WARNING: dax_upload'

DESCRIPTION = """What is the dax executable doing :
   * Upload all processes run through dax back to XNAT from the queue folder <{folder}>

Examples:
   * run dax_upload: dax_upload
   * run dax_upload and write output to a file: dax_upload -l /path/to/file.log
   * run dax_upload and send email warnings/errors: dax_upload -e ...@gmail.com
   * run dax_upload for a specific xnat: dax_upload --host https://...
   * run dax_upload for a specific xnat/username: dax_upload --host https://... -u admin
   * run dax_upload for a specific xnat/username: dax_upload --host https://... -u admin -p project1,project2
"""

########### SEVERAL HOSTS ###########


########### Functions ###########
def send_email(from_add, password, dests, subject, content, server):
    """
    Send email using the server/from/pws

    :param from_add: address to send the email from
    :param password: password for the email address
    :param dests: list of emails addresses to send to
    :param subject: subject for the email
    :param content: content of the email
    :param server: SMTP server used to send email.
    :return: None
    """
    # Create the container (outer) email message.
    msg = MIMEText(content)
    msg['Subject'] = subject
    msg['From'] = from_add
    msg['To'] = ','.join(dests)

    # Send the email via our own SMTP server.
    s_obj = smtplib.SMTP(server)
    s_obj.starttls()
    s_obj.login(from_add, password)
    s_obj.sendmail(from_add, dests, msg.as_string())
    s_obj.quit()

def send_warning_emails():
    """
    Send warning emails about the dax_upload queue

    :return: None
    """
    if WARNING_LIST and OPTIONS.emailaddress:
        content = WARNING_START_CONTENT
        for warning in WARNING_LIST:
            content += ' - %s\n' % (warning)
        content += WARNING_END_CONTENT
        if SMTP_FROM and SMTP_PASS and SMTP_HOST:
            send_email(SMTP_FROM, SMTP_PASS, OPTIONS.emailaddress.split(','),
                       WARNING_SUBJECT, content, SMTP_HOST)

def check_folders():
    """
    Check that the default folders exist and if not create them

    :return: None
    """
    #make the directories if they don't exist:
    if not os.path.exists(RESULTS_DIR):
        os.mkdir(RESULTS_DIR)
    if not os.path.exists(os.path.join(RESULTS_DIR, _OUTLOG)):
        os.mkdir(os.path.join(RESULTS_DIR, _OUTLOG))
    if not os.path.exists(os.path.join(RESULTS_DIR, _TRASH)):
        os.mkdir(os.path.join(RESULTS_DIR, _TRASH))
    if not os.path.exists(os.path.join(RESULTS_DIR, _PBS)):
        os.mkdir(os.path.join(RESULTS_DIR, _PBS))
    if not os.path.exists(os.path.join(RESULTS_DIR, _FLAG_FILES)):
        os.mkdir(os.path.join(RESULTS_DIR, _FLAG_FILES))

def select_assessor(xnat, assessor_dict):
    """
    Select the assessor pyxnat Eobject from the assessor dictionary information

    :param xnat: pyxnat.interface object
    :param assessor_dict: assessor dictionary
    :return: assessor pyxnat Eobject
    """
    return XnatUtils.select_obj(xnat,
                                assessor_dict['project_id'],
                                assessor_dict['subject_label'],
                                assessor_dict['session_label'],
                                assessor_id=assessor_dict['label'])

def is_dax_upload_running():
    """
    Check if dax_upload is not already running on the station

    :return: True if dax_upload already running, False otherwise.
    """
    if os.path.exists(DAX_UPLOAD_FLAGFILE):
        LOGGER.warn('Upload already running.')
        return True
    else:
        f_obj = open(DAX_UPLOAD_FLAGFILE, 'w')
        today = datetime.now()
        datestr = "Date: %s%s%s_%s:%s:%s" % (str(today.year),
                                             str(today.month),
                                             str(today.day),
                                             str(today.hour),
                                             str(today.minute),
                                             str(today.second))
        f_obj.write(datestr+'\n')
        f_obj.close()
        LOGGER.debug('Flagfile created: %s with date: %s\n' % (DAX_UPLOAD_FLAGFILE,
                                                               datestr))
        return False

def get_assessor_dict(assessor_label, assessor_path):
    """
    Generate the dictionary for an assessor from the folder in the queue

    :param assessor_label: assessor label
    :param assessor_path: assessor path on the station
    :return: None
    """
    assessor_dict = dict()
    keys = ['project_id', 'subject_label', 'session_label', 'label', 'proctype', 'path']
    labels = assessor_label.split('-x-')
    if len(labels) > 3:
        values = [labels[0], labels[1], labels[2], assessor_label, labels[-1], assessor_path]
        assessor_dict = dict(zip(keys, values))
    return assessor_dict

def get_assessor_list(projects):
    """
    Get the list of assessors labels to upload to XNAT from the queue folder.

    :param projects: list of projects to upload to XNAT
    :return: list of assessor to upload from upload folder
    """
    assessor_label_list = list()

    LOGGER.debug(' - Get Processes names from the upload folder...')
    #check all files/folder in the directory
    for assessor_label in os.listdir(RESULTS_DIR):
        if assessor_label in _UPLOAD_SKIP_LIST:
            continue

        # If projects set, check that the project is in the list of projects to upload to XNAT
        if projects and assessor_label.split('-x-')[0] not in projects:
            continue

        assessor_path = os.path.join(RESULTS_DIR, assessor_label)
        if not os.path.isdir(assessor_path):
            continue
        if os.path.exists(os.path.join(assessor_path, _EMAILED_FLAG_FILE)):
            continue
        if (os.path.exists(os.path.join(assessor_path, _READY_FLAG_FILE)) or\
           os.path.exists(os.path.join(assessor_path, _FAILED_FLAG_FILE))) and\
           (not is_diskq_assessor(assessor_label) or os.path.exists(os.path.join(assessor_path, _COMPLETE_FLAG_FILE))):
            # Passed all checks, so add it to upload list
            assessor_label_list.append(assessor_label)

    return assessor_label_list

def get_pbs_list(projects):
    """
    Get the list of PBS file to upload to XNAT.

    :param projects: list of projects to upload to XNAT
    :return: list of pbs file from the PBS folder
    """
    pbs_list = list()

    LOGGER.debug(' - Get the PBS for the processes...')
    #check all files/folder in the directory
    for pbs_name in os.listdir(os.path.join(RESULTS_DIR, _PBS)):

        # If projects set, check that the project is in the list of projects to upload to XNAT
        if projects and pbs_name.split('-x-')[0] not in projects:
            continue

        pbs_file = os.path.join(RESULTS_DIR, _PBS, pbs_name)
        if os.path.isfile(pbs_file):
            pbs_list.append(pbs_name)

    return pbs_list

def get_version_assessor(assessor_path):
    """
    Get the version of the assessor that we are uploading from text file

    :param assessor_path: path for the assessor
    :return: version of the assessor from the version.txt file
    """
    version = '1.0.0'
    if os.path.exists(os.path.join(assessor_path, 'version.txt')):
        f_obj = open(os.path.join(assessor_path, 'version.txt'), 'r')
        version = f_obj.read().strip()
        f_obj.close()
    return version

def generate_snapshots(assessor_path):
    """
    Generate Snapshots from the PDF if it exists.

    :param assessor_path: path for the assessor
    :return: None
    """
    snapshot_dir = os.path.join(assessor_path, 'SNAPSHOTS')
    snapshot_original = os.path.join(snapshot_dir, SNAPSHOTS_ORIGINAL)
    snapshot_preview = os.path.join(snapshot_dir, SNAPSHOTS_PREVIEW)
    if not os.path.exists(snapshot_original) and\
       os.path.exists(os.path.join(assessor_path, 'PDF')):
        LOGGER.debug('    +creating original of SNAPSHOTS')
        if not os.path.exists(snapshot_dir):
            os.mkdir(snapshot_dir)
        #Make the snapshots for the assessors with ghostscript
        cmd = GS_CMD.format(original=snapshot_original,
                            assessor_path=assessor_path)
        os.system(cmd)
    #Create the preview snapshot from the original if Snapshots exist :
    if os.path.exists(snapshot_original):
        LOGGER.debug('    +creating preview of SNAPSHOTS')
        #Make the snapshot_thumbnail
        cmd = CONVERT_CMD.format(original=snapshot_original,
                                 preview=snapshot_preview)
        os.system(cmd)

def copy_outlog(assessor_dict):
    """
    Copy the oulog files to the assessor folder if we are uploading the assessor

    :param assessor_dict: dictionary for the assessor
    :return: None
    """
    outlog_path = os.path.join(RESULTS_DIR, _OUTLOG,
                               assessor_dict['label']+'.output')
    new_outlog_path = os.path.join(assessor_dict['path'], _OUTLOG,
                                   assessor_dict['label']+'.output')
    if os.path.exists(outlog_path):
        os.makedirs(os.path.join(assessor_dict['path'], _OUTLOG))
        shutil.move(outlog_path, new_outlog_path)

def get_xsitype(assessor_dict):
    """
    Copy the oulog files to the assessor folder if we are uploading the assessor

    :param assessor_dict: dictionary for the assessor
    :return: xsitype for the assessor_dict
    """
    proctype = assessor_dict['proctype']
    if proctype.startswith('FS') and not proctype.startswith('FSL'):
        return XnatUtils.DEFAULT_FS_DATATYPE
    else:
        return XnatUtils.DEFAULT_DATATYPE

def is_complete(assessor_dict, procstatus):
    """
    Copy the oulog files to the assessor folder if we are uploading the assessor

    :param assessor_dict: dictionary for the assessor
    :param procstatus: status to set for the assessor
    :return: True if the assessor is Complete, False otherwise
    """
    if procstatus == READY_TO_COMPLETE or procstatus == COMPLETE:
        open(os.path.join(assessor_dict['path'], _EMAILED_FLAG_FILE), 'w').close()
        mess = """    - Assessor label : {label}\n"""
        message = mess.format(label=assessor_dict['label'])
        WARNING_LIST.append(message)
        LOGGER.warn('  -->Data already present on XNAT.\n')
        return True
    else:
        return False

def create_freesurfer_assessor(assessor_obj):
    """
    Create freesurfer specific assessor using the DEFAULT_FS_DATATYPE from dax

    :param assessor_obj: pyxnat assessor Eobject
    :return: None
    """
    #create the assessor and set the status
    assessor_obj.create(assessors=XnatUtils.DEFAULT_FS_DATATYPE,
                        **{XnatUtils.DEFAULT_FS_DATATYPE+'/fsversion':'0'})
    now = datetime.now()
    today = '%s-%s-%s-' % (str(now.year), str(now.month), str(now.day))

    assessor_obj.attrs.mset({XnatUtils.DEFAULT_FS_DATATYPE+'/validation/status': JOB_PENDING,
                             XnatUtils.DEFAULT_FS_DATATYPE+'/date': today})

def create_default_assessor(assessor_obj, proctype):
    """
    Create default assessor using the DEFAULT_DATATYPE from dax

    :param assessor_obj: pyxnat assessor Eobject
    :param proctype: proctype for the assessor
    :return: None
    """
    # Create the assessor and set attributes
    now = datetime.now()
    today = '%s-%s-%s-' % (str(now.year), str(now.month), str(now.day))

    assessor_obj.create(assessors=XnatUtils.DEFAULT_DATATYPE)
    # Call mset to only make a single HTTP request
    assessor_obj.attrs.mset({XnatUtils.DEFAULT_DATATYPE+'/validation/status': JOB_PENDING,
                             XnatUtils.DEFAULT_DATATYPE+'/proctype': proctype,
                             XnatUtils.DEFAULT_DATATYPE+'/date': today})


def should_upload_assessor(assessor_obj, assessor_dict, xsitype, version):
    """
    Check if the assessor is ready to be uploaded to XNAT

    :param assessor_obj: pyxnat assessor Eobject
    :param assessor_dict: assessor dictionary
    :param xsitype: xsitype for the assessor (fsData or proc:GenProcData, ...)
    :param version: version for the assessor
    :return: True if the assessor should be upload, False otherwise
    """
    if not assessor_obj.exists():
        if xsitype == XnatUtils.DEFAULT_FS_DATATYPE:
            create_freesurfer_assessor(assessor_obj)
        else:
            create_default_assessor(assessor_obj, assessor_dict['proctype'])
    else:
        # Check if not already complete assessor
        procstatus = assessor_obj.attrs.get(xsitype+'/procstatus')
        if is_complete(assessor_dict, procstatus):
            return False
    # set the status to UPLOADING
    assessor_obj.attrs.mset({xsitype+'/procstatus': UPLOADING,
                             xsitype+'/procversion': version})
    return True

def upload_assessor(xnat, assessor_dict):
    """
    Upload results to an assessor

    :param xnat: pyxnat.Interface object
    :param assessor_dict: assessor dictionary
    :return: None
    """
    #get spiderpath from version.txt file:
    version = get_version_assessor(assessor_dict['path'])
    session_obj = XnatUtils.select_obj(xnat,
                                       assessor_dict['project_id'],
                                       assessor_dict['subject_label'],
                                       assessor_dict['session_label'])
    if not session_obj.exists():
        LOGGER.error('Cannot upload assessor, session does not exist.')
        return True

    #Select assessor
    assessor_obj = session_obj.assessor(assessor_dict['label'])
    xsitype = get_xsitype(assessor_dict)

    if should_upload_assessor(assessor_obj, assessor_dict, xsitype, version):
        ## Before Upload ##
        generate_snapshots(assessor_dict['path'])
        copy_outlog(assessor_dict)

        #Upload the XML if FreeSurfer
        if xsitype == XnatUtils.DEFAULT_FS_DATATYPE:
            xmlpath = os.path.join(assessor_dict['path'], 'XML')
            if os.path.exists(xmlpath):
                LOGGER.debug('    +setting XML for FreeSurfer')
                xml_files_list = os.listdir(xmlpath)
                if len(xml_files_list) != 1:
                    fpath = assessor_dict['path']
                    LOGGER.error('cannot upload FreeSufer, unable to find XML file: %s' % (fpath))
                    return
                xml_path = os.path.join(assessor_dict['path'], 'XML', xml_files_list[0])
                assessor_obj.create(xml=xml_path, allowDataDeletion=False)

        ## Upload ## for each folder=resource in the assessor directory
        for resource in os.listdir(assessor_dict['path']):
            resource_path = os.path.join(assessor_dict['path'], resource)
            #Need to be in a folder to create the resource :
            if os.path.isdir(resource_path):
                LOGGER.debug('    +uploading %s' % (resource))
                upload_resource(assessor_obj, resource, resource_path)

        ## after Upload ##
        if is_diskq_assessor(assessor_dict['label']): # was this run using the DISKQ option
            # Read attributes
            ctask = ClusterTask(assessor_dict['label'], RESULTS_DIR, DISKQ_DIR)
            
            # Set on XNAT
            assessor_obj.attrs.mset({
                xsitype + '/procstatus': ctask.get_status(),
                xsitype + '/validation/status': NEEDS_QA,
                xsitype + '/jobid': ctask.get_jobid(),
                xsitype + '/jobnode': ctask.get_jobnode(),
                xsitype + '/memused': ctask.get_memused(),
                xsitype + '/walltimeused': ctask.get_walltime(),
                xsitype + '/jobstartdate': ctask.get_jobstartdate()
            })
            
            # Delete the task from diskq
            ctask.delete()
        elif os.path.exists(os.path.join(assessor_dict['path'], _READY_FLAG_FILE)):
            assessor_obj.attrs.set(xsitype + '/procstatus', READY_TO_COMPLETE)
        else:
            assessor_obj.attrs.set(xsitype+'/procstatus', JOB_FAILED)
            
        #Remove the folder
        shutil.rmtree(assessor_dict['path'])

def is_diskq_assessor(assr_label):
    # Does a batch file exist for this assessor?
    return os.path.exists(os.path.join(DISKQ_BATCH_DIR, assr_label + JOB_EXTENSION_FILE))

def upload_resource(assessor_obj, resource, resource_path):
    """
    Upload a resource folder to an assessor

    :param assessor_obj: pyxnat assessor Eobject
    :param resource: resource to upload
    :param resource_path: resource path on the station
    :return: None
    """
    if resource == 'SNAPSHOTS':
        upload_snapshots(assessor_obj, resource_path)
    else:
        rfiles_list = os.listdir(resource_path)
        if not rfiles_list:
            LOGGER.warn('No files in '+resource_path)
        elif len(rfiles_list) > 1 or os.path.isdir(rfiles_list[0]):
            XnatUtils.upload_folder_to_obj(resource_path, assessor_obj.out_resource(resource),
                                           resource, removeall=True)
        #One or two file, let just upload them:
        else:
            fpath = os.path.join(resource_path, rfiles_list[0])
            if rfiles_list[0].lower().endswith('.zip'):
                if assessor_obj.out_resource(resource).exists():
                    assessor_obj.out_resource(resource).delete()
                assessor_obj.out_resource(resource).put_zip(fpath, overwrite=True, extract=True)
            else:
                XnatUtils.upload_file_to_obj(fpath,
                                             assessor_obj.out_resource(resource),
                                             removeall=True)

def upload_snapshots(assessor_obj, resource_path):
    """
    Upload snapshots to an assessor

    :param assessor_obj: pyxnat assessor Eobject
    :param resource_path: resource path on the station
    :return: None
    """
    #Remove the previous Snapshots:
    if assessor_obj.out_resource('SNAPSHOTS').exists:
        assessor_obj.out_resource('SNAPSHOTS').delete()
    original = os.path.join(resource_path, SNAPSHOTS_ORIGINAL)
    thumbnail = os.path.join(resource_path, SNAPSHOTS_PREVIEW)
    status = XnatUtils.upload_assessor_snapshots(assessor_obj,
                                                 original,
                                                 thumbnail)
    if status:
        os.remove(original)
        os.remove(thumbnail)
    else:
        LOGGER.warn('No snapshots original or preview were uploaded')

    #Upload the rest of the files in snapshots
    if len(os.listdir(resource_path)) > 0:
        XnatUtils.upload_folder_to_obj(resource_path,
                                       assessor_obj.out_resource('SNAPSHOTS'),
                                       'SNAPSHOTS')

########################### Main Functions to Upload results/PBS/OUTLOG ###########################
def upload_assessors(xnat, projects):
    """
    Upload all assessors to XNAT

    :param xnat: pyxnat.Interface object
    :param projects: list of projects to upload to XNAT
    :return: None
    """
    #Get the assessor label from the directory :
    assessors_list = get_assessor_list(projects)
    number_of_processes = len(assessors_list)
    for index, assessor_label in enumerate(assessors_list):
        assessor_path = os.path.join(RESULTS_DIR, assessor_label)
        mess = """    *Process: {index}/{max} -- label: {label} / time: {time}"""
        LOGGER.info(mess.format(index=str(index+1),
                                max=str(number_of_processes),
                                label=assessor_label,
                                time=str(datetime.now())))

        assessor_dict = get_assessor_dict(assessor_label, assessor_path)
        if get_assessor_dict:
            upload_assessor(xnat, assessor_dict)
        else:
            LOGGER.warn('     --> wrong label')

def upload_pbs(xnat, projects):
    """
    Upload all pbs files to XNAT

    :param xnat: pyxnat.Interface object
    :param projects: list of projects to upload to XNAT
    :return: None
    """
    pbs_list = get_pbs_list(projects)
    number_pbs = len(pbs_list)
    for index, pbsfile in enumerate(pbs_list):
        pbs_fpath = os.path.join(RESULTS_DIR, _PBS, pbsfile)
        mess = """   *Uploading PBS {index}/{max} -- File name: {file}"""
        LOGGER.info(mess.format(index=str(index+1),
                                max=str(number_pbs),
                                file=pbsfile))
        assessor_label = os.path.splitext(pbsfile)[0]
        assessor_dict = get_assessor_dict(assessor_label, 'none')
        if not assessor_dict:
            LOGGER.warn('wrong assessor label for %s' % (pbsfile))
            os.rename(pbs_fpath, os.path.join(RESULTS_DIR, _TRASH, pbsfile))
        else:
            assessor_obj = select_assessor(xnat, assessor_dict)
            if not assessor_obj.exists():
                LOGGER.warn('assessor does not exist for %s' % (pbsfile))
                os.rename(pbs_fpath, os.path.join(RESULTS_DIR, _TRASH, pbsfile))
            else:
                resource_obj = assessor_obj.out_resource(_PBS)
                if resource_obj.exists():
                    label = assessor_dict['label']
                    LOGGER.warn('the PBS resource already exists for the assessor %s' % (label))
                    if  os.path.isdir(os.path.join(RESULTS_DIR, assessor_dict['label'])):
                        LOGGER.warn('Copying the pbs file in the assessor folder...')
                        assr_pbs_folder = os.path.join(RESULTS_DIR, assessor_dict['label'], _PBS)
                        if not os.path.exists(assr_pbs_folder):
                            os.mkdir(assr_pbs_folder)
                        os.rename(pbs_fpath, os.path.join(assr_pbs_folder, pbsfile))
                    else:
                        LOGGER.warn('Copying the pbs file in the TRASH ...')
                        os.rename(pbs_fpath, os.path.join(RESULTS_DIR, _TRASH, pbsfile))
                else:
                    #upload the file
                    status = XnatUtils.upload_file_to_obj(pbs_fpath, resource_obj)
                    if status:
                        os.remove(pbs_fpath)

def upload_outlog(xnat, projects):
    """
    Upload all outlog files to XNAT

    :param xnat: pyxnat.Interface object
    :param projects: list of projects to upload to XNAT
    :return: None
    """
    outlogs_list = os.listdir(os.path.join(RESULTS_DIR, _OUTLOG))
    if projects:
        outlogs_list = [logfile for logfile in outlogs_list if logfile.split('-x-')[0] in projects]

    number_outlog = len(outlogs_list)
    for index, outlogfile in enumerate(outlogs_list):
        outlog_fpath = os.path.join(RESULTS_DIR, _OUTLOG, outlogfile)
        mess = """   *Checking OUTLOG {index}/{max} -- File name: {file}"""
        LOGGER.info(mess.format(index=str(index+1),
                                max=str(number_outlog),
                                file=outlogfile))
        assessor_dict = get_assessor_dict(outlogfile[:-7], 'none')
        if not assessor_dict:
            LOGGER.warn('     wrong outlog file. You should remove it')
        else:
            assessor_obj = select_assessor(xnat, assessor_dict)
            xsitype = get_xsitype(assessor_dict)
            if not assessor_obj.exists():
                LOGGER.warn('     no assessor on XNAT -- moving file to trash.')
                os.rename(outlog_fpath, os.path.join(RESULTS_DIR, _TRASH, outlogfile))
            else:
                if assessor_obj.attrs.get(xsitype+'/procstatus') == JOB_FAILED:
                    resource_obj = assessor_obj.out_resource(_OUTLOG)
                    if resource_obj.exists():
                        pass
                    else:
                        LOGGER.info('     uploading file.')
                        status = XnatUtils.upload_file_to_obj(outlog_fpath, resource_obj)
                        if status:
                            os.remove(outlog_fpath)

def upload_results():
    """
    Main function to upload the results / PBS / OUTLOG of assessors
     from the queue folder

    :return: None
    """
    if len(os.listdir(RESULTS_DIR)) == 0:
        LOGGER.warn('No data need to be uploaded.\n')
        sys.exit()

    for upload_dict in UPLOAD_SETTINGS:
        try:
            LOGGER.info('===================================================================')
            proj_str = upload_dict['projects'] if upload_dict['projects'] else 'all'
            LOGGER.info('Connecting to XNAT <%s> to start uploading processes for projects: %s' % (upload_dict['host'], proj_str))
            xnat = XnatUtils.get_interface(host=upload_dict['host'], user=upload_dict['username'], pwd=upload_dict['password'])
            if not XnatUtils.has_dax_datatypes(xnat):
                raise Exception('error: dax datatypes are not installed on your xnat <%s>' % (upload_dict['host']))

            ################# 1) Upload the assessor data ###############
            #For each assessor label that need to be upload :
            LOGGER.info(' - Uploading results for assessors')
            upload_assessors(xnat, upload_dict['projects'])

            ################# 2) Upload the PBS files ###############
            #For each file, upload it to the PBS resource
            LOGGER.info(' - Uploading PBS files ...')
            upload_pbs(xnat, upload_dict['projects'])

            ################# 3) Upload the OUTLOG files not uploaded with processes ###############
            LOGGER.info(' - Checking OUTLOG files to upload them for JOB_FAILED jobs ...')
            upload_outlog(xnat, upload_dict['projects'])

        finally:
            xnat.disconnect()
            LOGGER.info('Connection to Xnat closed')
            LOGGER.info('===================================================================\n')
            send_warning_emails()

def load_upload_settings():
    """
    Method to parse arguments base on argparse

    :return: list of dictionaries info_dict
       info_dict for the host [key:value]:
        host : string for XNAT host
        username : string for XNAT username
        password : string for XNAT password
          (can be the environment variable containing the value)
        projects : list of projects to upload for the host
    """
    host_projs = list()
    #If settings file given, load it and use it:
    if OPTIONS.upload_settings:
        if not os.path.isfile(os.path.abspath(OPTIONS.upload_settings)):
            raise Exception('No upload settings file found: %s' % os.path.abspath(OPTIONS.upload_settings))
        if OPTIONS.upload_settings.endswith('.json'):
            with open(os.path.abspath(OPTIONS.upload_settings)) as data_file:
                host_projs = json.load(data_file)
        elif OPTIONS.upload_settings.endswith('.py'):
            settings = imp.load_source('settings', os.path.abspath(OPTIONS.upload_settings))
            host_projs = settings.host_projects
        elif OPTIONS.upload_settings.endswith('.csv'):
            with open(os.path.abspath(OPTIONS.upload_settings), 'rb') as csvfileread:
                csvreader = csv.reader(csvfileread, delimiter=',')
                for index, row in (csvreader):
                    if len(row) < 4:
                        raise Exception("error: could not read the csv row. Missing argument. 4 needed, %s found at line %s." % (str(len(row)), str(index)))
                    else:
                        if row != DEFAULT_HEADER:
                            host_projs.append(dict(zip(DEFAULT_HEADER, row[:4])))
        else:
            raise Exception("error: doesn't recognize the file format for the settings file. Please use either JSON/PYTHON/CSV format.")
    else: #if not file, use the environment variables and options
        host = os.environ['XNAT_HOST']
        username = None
        password = None
        projects = []
        if OPTIONS.host:
            host = OPTIONS.host
        if OPTIONS.projects:
            projects = OPTIONS.projects.split(',')
        if OPTIONS.username:
            username = OPTIONS.username
            if not OPTIONS.password:
                MSG = "Please provide the password for user <%s> on xnat(%s):" % (OPTIONS.username, host)
                password = getpass.getpass(prompt=MSG)
                if not password:
                    raise Exception('error: the password entered was empty. please provide a password')
            elif OPTIONS.password in os.environ:
                password = os.environ[OPTIONS.password]
            else:
                password =  OPTIONS.password
        host_projs.append(dict(zip(DEFAULT_HEADER, [host, username, password, projects])))
    return host_projs

def print_upload_settings():
    """
    Display Host/Username/Projects that will be used to upload data from the queue

    :return: None
    """
    LOGGER.info('Upload Settings selected by user:')
    for info in UPLOAD_SETTINGS:
        proj_str = ','.join(info['projects']) if info['projects'] else 'all'
        user_str = info['username'] if info['username'] else os.environ['XNAT_USER']
        LOGGER.info('XNAT Host: %s -- Xnat Username: %s -- projects: %s' % (info['host'], user_str, proj_str))
    LOGGER.info('Upload Directory: %s ' % (RESULTS_DIR))

def parse_args():
    """
    Method to parse arguments base on argparse

    :return: parser object
    """
    from argparse import ArgumentParser, RawTextHelpFormatter
    description = DESCRIPTION.format(folder=RESULTS_DIR)
    ap = ArgumentParser(prog='dax_upload', description=description,
                        formatter_class=RawTextHelpFormatter)
    ap.add_argument('--host', dest='host', default=None,
                    help='Host for XNAT. Default: using $XNAT_HOST.')
    ap.add_argument('-u', '--username', dest='username', default=None,
                    help='Username for XNAT. Default: using $XNAT_USER.')
    ap.add_argument('--pwd', dest='password', default=None,
                    help="Password for XNAT. You can specify the environment's variable for this option. Default: using $XNAT_PASS.")
    ap.add_argument('-s', '--suffix', dest='suffix', default="",
                    help='Suffix for the flagfile for dax_upload (Use this option if you use different XNAT_HOST).')
    ap.add_argument('-p', '--projects', dest='projects', default=None,
                    help='List of projects to upload to XNAT from the queue.')
    ap.add_argument('-f', '--uploadFileSettings', dest='upload_settings', default=None,
                    help='File describing each XNAT host and projects to upload  (.py/.csv/.json).')
    ap.add_argument('-e', '--email', dest='emailaddress', default=None,
                    help='Email address to inform you about the warnings and errors.')
    ap.add_argument('-l', '--logfile', dest='logfile',
                    help='Logs file path if needed.', default=None)
    ap.add_argument('--nodebug', dest='debug', action='store_false', help='Avoid printing DEBUG information.')
    return ap.parse_args()

if __name__ == '__main__':
    OPTIONS = parse_args()
    #Local Variables
    FLAG_FILES_LIST = list()
    WARNING_LIST = list()
    #Logger for logs
    LOGGER = dax.bin.set_logger(OPTIONS.logfile, OPTIONS.debug)
    LOGGER.info('Time at the beginning of the Process_Upload: '+str(datetime.now())+'\n')
    #Check if folders exist
    check_folders()
    DAX_UPLOAD_FLAGFILE = "%s%s.txt" % (FLAGFILE_TEMPLATE, OPTIONS.suffix)
    #Load the settings for upload
    UPLOAD_SETTINGS = load_upload_settings()
    print_upload_settings()
    #create the flag file showing that the spider is running
    if is_dax_upload_running():
        sys.exit()
    else:
        try:
            upload_results()
        finally:
            #remove flagfile
            os.remove(DAX_UPLOAD_FLAGFILE)
